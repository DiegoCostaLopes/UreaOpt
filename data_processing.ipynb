{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script creates the full database for chosen crops\n",
    "crops = ['cocoa', 'coffee', 'corn', 'rice', 'soy', 'sugarcane']\n",
    "rename_cols = {\n",
    "    'Local': 'name',\n",
    "    'Área destinada à colheita (Hectares)': 'area_planted',\n",
    "    'Área plantada (Hectares)': 'area_planted',\n",
    "    'Área colhida (Hectares)': 'area_harvested',\n",
    "    'Quantidade produzida (Toneladas)': 'production',\n",
    "    'Rendimento médio da produção (Quilogramas por Hectare)': 'yield',\n",
    "    'UF': 'state',\n",
    "    'Tipo região': 'region_type'\n",
    "}\n",
    "\n",
    "start_cols = ['name', 'state', 'region_type']\n",
    "\n",
    "data_pam = pd.DataFrame(columns=start_cols)\n",
    "\n",
    "# for filename in filenames:\n",
    "#     df_temp = pd.read_excel('data/processed/' + filename + '.xlsx').rename(columns=rename_cols)\n",
    "#     df_temp['crop'] = filename\n",
    "#     df = pd.concat([df, df_temp])\n",
    "\n",
    "for crop in crops:\n",
    "\n",
    "    rename_cols = {\n",
    "        'Local': 'name',\n",
    "        'Área destinada à colheita (Hectares)': 'area_planted_' + crop,\n",
    "        'Área plantada (Hectares)': 'area_planted_' + crop,\n",
    "        'Área colhida (Hectares)': 'area_harvested_' + crop,\n",
    "        'Quantidade produzida (Toneladas)': 'production_' + crop,\n",
    "        'Rendimento médio da produção (Quilogramas por Hectare)': 'yield_' + crop,\n",
    "        'UF': 'state',\n",
    "        'Tipo região': 'region_type',\n",
    "        'Valor da produção (Mil Reais)': 'value_' + crop,\n",
    "    }\n",
    "\n",
    "    df_temp = pd.read_excel('data/processed/' + crop + '.xlsx').rename(columns=rename_cols)\n",
    "    data_pam = data_pam.merge(df_temp, on=['name', 'state', 'region_type'], how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script creates the database only with production columns, more focused in my work.\n",
    "crops = ['cocoa', 'coffee', 'corn', 'rice', 'soy', 'sugarcane']\n",
    "start_cols = ['name', 'state', 'location_type']\n",
    "data_pam = pd.DataFrame(columns=start_cols)\n",
    "\n",
    "for crop in crops:\n",
    "\n",
    "    rename_cols = {\n",
    "        'Local': 'name',\n",
    "        'Quantidade produzida (Toneladas)': crop,\n",
    "        'UF': 'state',\n",
    "        'Tipo região': 'location_type',\n",
    "    }\n",
    "\n",
    "    df_temp = pd.read_excel('data/processed/' + crop + '.xlsx').rename(columns=rename_cols)\n",
    "    df_temp = df_temp[rename_cols.values()].drop_duplicates()\n",
    "    data_pam = data_pam.merge(df_temp, on=['name', 'state', 'location_type'], how='outer')\n",
    "    \n",
    "# cleaning strings up\n",
    "\n",
    "data_pam['name'] = data_pam['name'].apply(unidecode)\n",
    "data_pam['state'] = data_pam['state'].apply(unidecode)\n",
    "data_pam['location_type'] = (data_pam['location_type'].apply(unidecode).str\n",
    "                       .replace('Municipio', 'city')\n",
    "                       .replace('Microrregiao', 'microregion')\n",
    "                       .replace('Mesorregiao', 'macroregion')\n",
    "                       .replace('UF', 'state'))\n",
    "# putting all productions int64o the same df\n",
    "\n",
    "\n",
    "data_pam.to_csv('data/processed/data_pam_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rename_cols = {\n",
    "    'Nome município': 'name',\n",
    "    'Código IBGE município': 'id_city',\n",
    "    'Nome microrregião': 'microregion',\n",
    "    'Código IBGE microrregião': 'id_microregion',\n",
    "    'Nome mesorregião': 'macroregion',\n",
    "    'Código IBGE mesorregião': 'id_macroregion',\n",
    "    'Nome UF': 'state',\n",
    "    'Código IBGE UF': 'id_state',\n",
    "    'Sigla UF': 'UF',\n",
    "    'Nome região': 'region'\n",
    "}\n",
    "data_ibge_city = pd.read_excel('data/raw/ibge_codes/municipios.xlsx').rename(columns=rename_cols)\n",
    "data_ibge_city['location_type'] = 'city'\n",
    "data_ibge_city['id'] = data_ibge_city['id_city'].astype('int64')\n",
    "str_columns = ['name', 'microregion','macroregion','state','UF','region']\n",
    "for col in str_columns:\n",
    "    data_ibge_city[col] = data_ibge_city[col].apply(unidecode)\n",
    "    \n",
    "data_ibge_microregion = pd.read_excel('data/raw/ibge_codes/microrregiao.xlsx').rename(columns=rename_cols)\n",
    "data_ibge_microregion['name'] = data_ibge_microregion['microregion']\n",
    "data_ibge_microregion['location_type'] = 'microregion'\n",
    "data_ibge_microregion['id'] = data_ibge_microregion['id_microregion'].astype('int64')\n",
    "str_columns = ['name', 'microregion', 'macroregion','state','UF','region']\n",
    "\n",
    "for col in str_columns:\n",
    "    data_ibge_microregion[col] = data_ibge_microregion[col].apply(unidecode)\n",
    "\n",
    "data_ibge_macroregion = pd.read_excel('data/raw/ibge_codes/mesorregiao.xlsx').rename(columns=rename_cols)\n",
    "data_ibge_macroregion['name'] = data_ibge_macroregion['macroregion']\n",
    "data_ibge_macroregion['location_type'] = 'macroregion'\n",
    "data_ibge_macroregion['id'] = data_ibge_macroregion['id_macroregion'].astype('int64')\n",
    "str_columns = ['name','state', 'macroregion', 'UF','region']\n",
    "\n",
    "for col in str_columns:\n",
    "    data_ibge_macroregion[col] = data_ibge_macroregion[col].apply(unidecode)\n",
    "\n",
    "data_ibge_state = pd.read_excel('data/raw/ibge_codes/uf.xlsx').rename(columns=rename_cols)\n",
    "data_ibge_state['name'] = data_ibge_state['state']\n",
    "data_ibge_state['location_type'] = 'state'\n",
    "data_ibge_state['id'] = data_ibge_state['id_state'].astype('int64')\n",
    "str_columns = ['name', 'state', 'UF','region']\n",
    "\n",
    "for col in str_columns:\n",
    "    data_ibge_state[col] = data_ibge_state[col].apply(unidecode)\n",
    "\n",
    "data_ibge = pd.concat([data_ibge_city, data_ibge_microregion, data_ibge_macroregion, data_ibge_state])\n",
    "\n",
    "data_ibge.to_csv('data/processed/data_ibge.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_pam.merge(data_ibge, on=['name', 'location_type', 'state'], how='inner')\n",
    "crops = ['cocoa', 'coffee', 'corn', 'rice', 'soy', 'sugarcane']\n",
    "df['total'] = df[crops].sum(axis=1)\n",
    "df = df.set_index('id')\n",
    "\n",
    "# id_columns = ['id', 'id_microregion', 'id_macroregion', 'id_state']\n",
    "# df[id_columns] = df[id_columns].astype('int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each microregion, finding out what is the city with maximum production. that will be the reference city for distance purposes.\n",
    "\n",
    "df.loc[df['location_type'] == 'microregion', 'total'] = 0\n",
    "grouped = df.groupby('microregion')\n",
    "\n",
    "df['reference_id'] = grouped['total'].transform('idxmax')\n",
    "\n",
    "\n",
    "\n",
    "# grouped['reference_id'] = df.loc[df['total'].idxmax(), 'id']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
